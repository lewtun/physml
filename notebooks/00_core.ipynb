{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp core"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Core library\n",
    "\n",
    "> Helper functions used throughout the lessons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "import pandas as pd\n",
    "from nbdev.showdoc import *\n",
    "import os\n",
    "import gdown\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import plot_tree\n",
    "from pathlib import Path\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def download_dataset(dataset_name: str):\n",
    "    \"\"\"Download datasets from Google Drive.\"\"\"\n",
    "\n",
    "    name_to_id = {\n",
    "        \"susy.csv.gz\": \"1rnR1v-BkMOtzV80R7jFyU1cwO3fGYrQs\",\n",
    "        \"susy.feather\": \"1PxCruwO42GV7FKtwZDXah7iGjDib7YPM\",\n",
    "        \"susy_train.feather\": \"1ezeCZycZ3BrEh-qOLiSJF40YowYEbbTH\",\n",
    "        \"susy_test.feather\": \"1UM8sheb4jzQa16haG6HnVbpJCxZwN2yE\",\n",
    "        \"susy_sample.feather\": \"1l4x_uBeup4eciLDK4YjnfY_G8yTpXLkP\",\n",
    "        \"shapes.zip\": \"1qV-BHzkgwHt8r61Ycf4p9l0CllOQr7I9\",\n",
    "        \"Cells.jpg\": \"1D841Ny9DXAcpgsOTmhgGTahAp4yCWaBh\",\n",
    "        \"BlackHole.jpg\": \"1X1hn31N5n17KQpWw1fXi8Da5CjTTxv0i\",\n",
    "        \"diagrams_basic.pkl\": \"1TJiqCarlcPDk5he_ABscizWhsm_ZIeMG\",\n",
    "        \"diagrams.pkl\": \"1oq9j6oBclSK1u_eVfFeWWktNVuD31neh\"\n",
    "    }\n",
    "\n",
    "    path = \"../data/\"\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "    gdrive_path = \"https://drive.google.com/uc?id=\"\n",
    "    if dataset_name in name_to_id:\n",
    "        if os.path.exists(path + dataset_name):\n",
    "            print(\n",
    "                f\"Dataset already exists at '{path + dataset_name}' and is not downloaded again.\"\n",
    "            )\n",
    "            return\n",
    "        try:\n",
    "            file_url = gdrive_path + name_to_id[dataset_name]\n",
    "            gdown.download(file_url, path + dataset_name, quiet=True)\n",
    "        except Exception as e:\n",
    "            print(\"Something went wrong during the download! Try again.\")\n",
    "            raise e\n",
    "        print(f\"Download of {dataset_name} dataset complete.\")\n",
    "    else:\n",
    "        raise KeyError(\"File not on Google Drive.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SUSY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The SUSY dataset from the [UCI Machine Learning repository](http://archive.ics.uci.edu/ml/datasets/SUSY#):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download of susy.csv.gz dataset complete.\n"
     ]
    }
   ],
   "source": [
    "download_dataset(\"susy.csv.gz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A compressed version in [feather format](https://blog.rstudio.com/2016/03/29/feather/) is also available for faster loading in-class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download of susy.feather dataset complete.\n"
     ]
    }
   ],
   "source": [
    "download_dataset(\"susy.feather\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the training (first 4,500,000 rows) and test (last 500,000 rows) sets, run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download of susy_train.feather dataset complete.\n",
      "Download of susy_test.feather dataset complete.\n"
     ]
    }
   ],
   "source": [
    "download_dataset(\"susy_train.feather\")\n",
    "download_dataset(\"susy_test.feather\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get a random sample of 100,000 rows from `susy_train`, run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download of susy_sample.feather dataset complete.\n"
     ]
    }
   ],
   "source": [
    "download_dataset(\"susy_sample.feather\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topological data analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the 3D shape classification task in lesson 6, you can download the ZIP file of real-world objects as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download of shapes.zip dataset complete.\n"
     ]
    }
   ],
   "source": [
    "download_dataset(\"shapes.zip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also provide precomputed persistence diagrams so you can save time when running on Binder / Colab:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download of diagrams_basic.pkl dataset complete.\n",
      "Download of diagrams.pkl dataset complete.\n"
     ]
    }
   ],
   "source": [
    "# circles, spheres, tori\n",
    "download_dataset(\"diagrams_basic.pkl\")\n",
    "# real-world objects\n",
    "download_dataset(\"diagrams.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the computer vision experiments, you can download the images as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download of Cells.jpg dataset complete.\n",
      "Download of BlackHole.jpg dataset complete.\n"
     ]
    }
   ],
   "source": [
    "download_dataset(\"Cells.jpg\")\n",
    "download_dataset(\"BlackHole.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def make_point_clouds(n_samples_per_shape: int, n_points: int, noise: float):\n",
    "    \"\"\"Make point clouds for circles, spheres, and tori with random noise.\n",
    "    \"\"\"\n",
    "    circle_point_clouds = [\n",
    "        np.asarray(\n",
    "            [\n",
    "                [np.sin(t) + noise * (np.random.rand(1)[0] - 0.5), np.cos(t) + noise * (np.random.rand(1)[0] - 0.5), 0]\n",
    "                for t in range((n_points ** 2))\n",
    "            ]\n",
    "        )\n",
    "        for kk in range(n_samples_per_shape)\n",
    "    ]\n",
    "    # label circles with 0\n",
    "    circle_labels = np.zeros(n_samples_per_shape)\n",
    "\n",
    "    sphere_point_clouds = [\n",
    "        np.asarray(\n",
    "            [\n",
    "                [\n",
    "                    np.cos(s) * np.cos(t) + noise * (np.random.rand(1)[0] - 0.5),\n",
    "                    np.cos(s) * np.sin(t) + noise * (np.random.rand(1)[0] - 0.5),\n",
    "                    np.sin(s) + noise * (np.random.rand(1)[0] - 0.5),\n",
    "                ]\n",
    "                for t in range(n_points)\n",
    "                for s in range(n_points)\n",
    "            ]\n",
    "        )\n",
    "        for kk in range(n_samples_per_shape)\n",
    "    ]\n",
    "    # label spheres with 1\n",
    "    sphere_labels = np.ones(n_samples_per_shape)\n",
    "\n",
    "    torus_point_clouds = [\n",
    "        np.asarray(\n",
    "            [\n",
    "                [\n",
    "                    (2 + np.cos(s)) * np.cos(t) + noise * (np.random.rand(1)[0] - 0.5),\n",
    "                    (2 + np.cos(s)) * np.sin(t) + noise * (np.random.rand(1)[0] - 0.5),\n",
    "                    np.sin(s) + noise * (np.random.rand(1)[0] - 0.5),\n",
    "                ]\n",
    "                for t in range(n_points)\n",
    "                for s in range(n_points)\n",
    "            ]\n",
    "        )\n",
    "        for kk in range(n_samples_per_shape)\n",
    "    ]\n",
    "    # label tori with 2\n",
    "    torus_labels = 2 * np.ones(n_samples_per_shape)\n",
    "\n",
    "    point_clouds = np.concatenate((circle_point_clouds, sphere_point_clouds, torus_point_clouds))\n",
    "    labels = np.concatenate((circle_labels, sphere_labels, torus_labels))\n",
    "\n",
    "    return point_clouds, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def load_shapes(path: Path, classes: List, n_points: int) -> pd.DataFrame:\n",
    "    \"\"\"Load 3D shapes as a single pandas.DataFrame.\n",
    "    \"\"\"\n",
    "    point_clouds = pd.DataFrame(columns=[\"x\", \"y\", \"z\", \"label\"])\n",
    "\n",
    "    for c in classes:\n",
    "        for p in path.rglob(\"*.pts\"):\n",
    "            if c in p.name:\n",
    "                # ignore color columns\n",
    "                df = pd.read_csv(p, names=[\"x\", \"y\", \"z\", \"r\", \"g\", \"b\"], usecols=[\"x\", \"y\", \"z\"], sep=\" \").sample(\n",
    "                    n_points\n",
    "                )\n",
    "                df[\"label\"] = p.stem\n",
    "                point_clouds = point_clouds.append(df, ignore_index=True)\n",
    "\n",
    "    return point_clouds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data wrangling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def display_large(df):\n",
    "    \"\"\"Displays up to 1000 columns and rows of pandas.DataFrame or pandas.Series objects.\"\"\"\n",
    "    with pd.option_context(\"display.max_rows\", 1000, \"display.max_columns\", 1000):\n",
    "        display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def rf_feature_importance(fitted_model, df):\n",
    "    \"Creates a pandas.Dataframe of a Random Forest's feature importance per column.\"\n",
    "    return pd.DataFrame(\n",
    "        {\"Column\": df.columns, \"Importance\": fitted_model.feature_importances_}\n",
    "    ).sort_values(\"Importance\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def plot_feature_importance(feature_importance):\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "    return sns.barplot(y=\"Column\", x=\"Importance\", data=feature_importance, color=\"b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def plot_regression_tree(fitted_model, feature_names, fontsize=18):\n",
    "    # we need to specify the background color because of a quirk in sklearn\n",
    "    fig, ax = plt.subplots(figsize=(30, 10), facecolor='k')\n",
    "    # generate tree plot\n",
    "    plot_tree(\n",
    "        fitted_model,\n",
    "        filled=True,\n",
    "        feature_names=feature_names,\n",
    "        ax=ax,\n",
    "        fontsize=fontsize,\n",
    "    )\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def plot_predictions(regressors, X, y, axes, label=None, style=\"r-\", data_style=\"b.\", data_label=None):\n",
    "    x1 = np.linspace(axes[0], axes[1], len(y))\n",
    "    y_pred = sum(regressor.predict(x1.reshape(-1, 1)) for regressor in regressors)\n",
    "    plt.plot(X[:, 0], y, data_style, label=data_label)\n",
    "    plt.plot(x1, y_pred, style, linewidth=2, label=label)\n",
    "    if label or data_label:\n",
    "        plt.legend(loc=\"upper center\", fontsize=16)\n",
    "    plt.axis(axes)\n",
    "    plt.ylabel(\"$y$\", fontsize=16)\n",
    "    plt.xlabel(\"$X$\", fontsize=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
