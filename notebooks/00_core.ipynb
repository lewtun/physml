{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp core"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Core library\n",
    "\n",
    "> Helper functions used throughout the lessons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "import pandas as pd\n",
    "from nbdev.showdoc import *\n",
    "import os\n",
    "import gdown\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def download_dataset(dataset_name: str):\n",
    "    \"\"\"Download datasets from Google Drive.\"\"\"\n",
    "\n",
    "    name_to_id = {\n",
    "        \"tau_decays_train.csv\": \"1iVSiZ0jLwf2_wi4Cyk2bU9O99RoTl4QF\",\n",
    "        \"tau_decays_test.csv\": \"1t9HNGjlP9Zt0PDYZjJNu90BgRymvbaT8\",\n",
    "        \"tau_decays_check_agreement.csv\": \"12jD2rxJUTJ5O9Wt457B_njl0ZxQTFKTG\",\n",
    "        \"tau_decays_check_correlation.csv\": \"18E7v81v5iCY86PwLeOWxQxZdsPcCEXQE\"\n",
    "    }\n",
    "    \n",
    "    path = \"../data/\"\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "    gdrive_path = \"https://drive.google.com/uc?id=\"\n",
    "    if dataset_name in name_to_id:\n",
    "        if os.path.exists(path + dataset_name):\n",
    "            print(\n",
    "                f\"Dataset already exists at '{path + dataset_name}' and is not downloaded again.\"\n",
    "            )\n",
    "            return\n",
    "        try:\n",
    "            file_url = gdrive_path + name_to_id[dataset_name]\n",
    "            gdown.download(file_url, path + dataset_name, quiet=True)\n",
    "        except Exception as e:\n",
    "            print(\"Something went wrong during the download! Try again.\")\n",
    "            raise e\n",
    "        print(f\"Download of {dataset_name} dataset complete.\")\n",
    "    else:\n",
    "        raise KeyError(\"File not on Google Drive.\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flavours of physics: finding τ → μμμ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train, test and evaluation datasets for Kaggle's flavour of physics challenge (link [here](https://www.kaggle.com/c/flavours-of-physics/overview)):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download of tau_decays_train.csv dataset complete.\n"
     ]
    }
   ],
   "source": [
    "download_dataset(\"tau_decays_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download of tau_decays_test.csv dataset complete.\n"
     ]
    }
   ],
   "source": [
    "download_dataset(\"tau_decays_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download of tau_decays_check_agreement.csv dataset complete.\n"
     ]
    }
   ],
   "source": [
    "download_dataset(\"tau_decays_check_agreement.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download of tau_decays_check_correlation.csv dataset complete.\n"
     ]
    }
   ],
   "source": [
    "download_dataset(\"tau_decays_check_correlation.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data wrangling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def display_large(df):\n",
    "    \"\"\"Displays up to 1000 columns and rows of pandas.DataFrame or pandas.Series objects.\"\"\"\n",
    "    with pd.option_context(\"display.max_rows\", 1000, \"display.max_columns\", 1000):\n",
    "        display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def rf_feature_importance(fitted_model, df):\n",
    "    \"Creates a pandas.Dataframe of a Random Forest's feature importance per column.\"\n",
    "    return pd.DataFrame(\n",
    "        {\"Column\": df.columns, \"Importance\": fitted_model.feature_importances_}\n",
    "    ).sort_values(\"Importance\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def plot_feature_importance(feature_importance):\n",
    "    fig, ax = plt.subplots(figsize=(12,8))\n",
    "    return sns.barplot(y=\"Column\", x=\"Importance\", data=feature_importance, color=\"b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
