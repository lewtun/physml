{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation functions for τ → 3μ\n",
    "\n",
    "> Useful helper functions to evaluate model predictions from Kaggle's Flavours of Physics competition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "# Copyright 2015 Tatiana Likhomanenko and Alexey Rogozhnikov\n",
    "# Source: https://github.com/yandexdataschool/flavours-of-physics-start/blob/master/evaluation.py\n",
    "#\n",
    "# Copyright 2020 Lewis Tunstall\n",
    "#\n",
    "# This file has been modified by Lewis Tunstall to be included in an nbdev development environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "import numpy\n",
    "from sklearn.metrics import roc_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def __rolling_window(data, window_size):\n",
    "    \"\"\"\n",
    "    Rolling window: take window with definite size through the array\n",
    "    :param data: array-like\n",
    "    :param window_size: size\n",
    "    :return: the sequence of windows\n",
    "    Example: data = array(1, 2, 3, 4, 5, 6), window_size = 4\n",
    "        Then this function return array(array(1, 2, 3, 4), array(2, 3, 4, 5), array(3, 4, 5, 6))\n",
    "    \"\"\"\n",
    "    shape = data.shape[:-1] + (data.shape[-1] - window_size + 1, window_size)\n",
    "    strides = data.strides + (data.strides[-1],)\n",
    "    return numpy.lib.stride_tricks.as_strided(data, shape=shape, strides=strides)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def __cvm(subindices, total_events):\n",
    "    \"\"\"\n",
    "    Compute Cramer-von Mises metric.\n",
    "    Compared two distributions, where first is subset of second one.\n",
    "    Assuming that second is ordered by ascending\n",
    "    :param subindices: indices of events which will be associated with the first distribution\n",
    "    :param total_events: count of events in the second distribution\n",
    "    :return: cvm metric\n",
    "    \"\"\"\n",
    "    target_distribution = numpy.arange(1, total_events + 1, dtype='float') / total_events\n",
    "    subarray_distribution = numpy.cumsum(numpy.bincount(subindices, minlength=total_events), dtype='float')\n",
    "    subarray_distribution /= 1.0 * subarray_distribution[-1]\n",
    "    return numpy.mean((target_distribution - subarray_distribution) ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def compute_cvm(predictions, masses, n_neighbours=200, step=50):\n",
    "    \"\"\"\n",
    "    Computing Cramer-von Mises (cvm) metric on background events: take average of cvms calculated for each mass bin.\n",
    "    In each mass bin global prediction's cdf is compared to prediction's cdf in mass bin.\n",
    "    :param predictions: array-like, predictions\n",
    "    :param masses: array-like, in case of Kaggle tau23mu this is reconstructed mass\n",
    "    :param n_neighbours: count of neighbours for event to define mass bin\n",
    "    :param step: step through sorted mass-array to define next center of bin\n",
    "    :return: average cvm value\n",
    "    \"\"\"\n",
    "    predictions = numpy.array(predictions)\n",
    "    masses = numpy.array(masses)\n",
    "    assert len(predictions) == len(masses)\n",
    "\n",
    "    # First, reorder by masses\n",
    "    predictions = predictions[numpy.argsort(masses)]\n",
    "\n",
    "    # Second, replace probabilities with order of probability among other events\n",
    "    predictions = numpy.argsort(numpy.argsort(predictions, kind='mergesort'), kind='mergesort')\n",
    "\n",
    "    # Now, each window forms a group, and we can compute contribution of each group to CvM\n",
    "    cvms = []\n",
    "    for window in __rolling_window(predictions, window_size=n_neighbours)[::step]:\n",
    "        cvms.append(__cvm(subindices=window, total_events=len(predictions)))\n",
    "    return numpy.mean(cvms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def __roc_curve_splitted(data_zero, data_one, sample_weights_zero, sample_weights_one):\n",
    "    \"\"\"\n",
    "    Compute roc curve\n",
    "    :param data_zero: 0-labeled data\n",
    "    :param data_one:  1-labeled data\n",
    "    :param sample_weights_zero: weights for 0-labeled data\n",
    "    :param sample_weights_one:  weights for 1-labeled data\n",
    "    :return: roc curve\n",
    "    \"\"\"\n",
    "    labels = [0] * len(data_zero) + [1] * len(data_one)\n",
    "    weights = numpy.concatenate([sample_weights_zero, sample_weights_one])\n",
    "    data_all = numpy.concatenate([data_zero, data_one])\n",
    "    fpr, tpr, _ = roc_curve(labels, data_all, sample_weight=weights)\n",
    "    return fpr, tpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def compute_ks(data_prediction, mc_prediction, weights_data, weights_mc):\n",
    "    \"\"\"\n",
    "    Compute Kolmogorov-Smirnov (ks) distance between real data predictions cdf and Monte Carlo one.\n",
    "    :param data_prediction: array-like, real data predictions\n",
    "    :param mc_prediction: array-like, Monte Carlo data predictions\n",
    "    :param weights_data: array-like, real data weights\n",
    "    :param weights_mc: array-like, Monte Carlo weights\n",
    "    :return: ks value\n",
    "    \"\"\"\n",
    "    assert len(data_prediction) == len(weights_data), 'Data length and weight one must be the same'\n",
    "    assert len(mc_prediction) == len(weights_mc), 'Data length and weight one must be the same'\n",
    "\n",
    "    data_prediction, mc_prediction = numpy.array(data_prediction), numpy.array(mc_prediction)\n",
    "    weights_data, weights_mc = numpy.array(weights_data), numpy.array(weights_mc)\n",
    "\n",
    "    assert numpy.all(data_prediction >= 0.) and numpy.all(data_prediction <= 1.), 'Data predictions are out of range [0, 1]'\n",
    "    assert numpy.all(mc_prediction >= 0.) and numpy.all(mc_prediction <= 1.), 'MC predictions are out of range [0, 1]'\n",
    "\n",
    "    weights_data /= numpy.sum(weights_data)\n",
    "    weights_mc /= numpy.sum(weights_mc)\n",
    "\n",
    "    fpr, tpr = __roc_curve_splitted(data_prediction, mc_prediction, weights_data, weights_mc)\n",
    "\n",
    "    Dnm = numpy.max(numpy.abs(fpr - tpr))\n",
    "    return Dnm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def roc_auc_truncated(labels, predictions, tpr_thresholds=(0.2, 0.4, 0.6, 0.8),\n",
    "                      roc_weights=(4, 3, 2, 1, 0)):\n",
    "    \"\"\"\n",
    "    Compute weighted area under ROC curve.\n",
    "    :param labels: array-like, true labels\n",
    "    :param predictions: array-like, predictions\n",
    "    :param tpr_thresholds: array-like, true positive rate thresholds delimiting the ROC segments\n",
    "    :param roc_weights: array-like, weights for true positive rate segments\n",
    "    :return: weighted AUC\n",
    "    \"\"\"\n",
    "    assert numpy.all(predictions >= 0.) and numpy.all(predictions <= 1.), 'Data predictions are out of range [0, 1]'\n",
    "    assert len(tpr_thresholds) + 1 == len(roc_weights), 'Incompatible lengths of thresholds and weights'\n",
    "    fpr, tpr, _ = roc_curve(labels, predictions)\n",
    "    area = 0.\n",
    "    tpr_thresholds = [0.] + list(tpr_thresholds) + [1.]\n",
    "    for index in range(1, len(tpr_thresholds)):\n",
    "        tpr_cut = numpy.minimum(tpr, tpr_thresholds[index])\n",
    "        tpr_previous = numpy.minimum(tpr, tpr_thresholds[index - 1])\n",
    "        area += roc_weights[index - 1] * (auc(fpr, tpr_cut) - auc(fpr, tpr_previous))\n",
    "    tpr_thresholds = numpy.array(tpr_thresholds)\n",
    "    # roc auc normalization to be 1 for an ideal classifier\n",
    "    area /= numpy.sum((tpr_thresholds[1:] - tpr_thresholds[:-1]) * numpy.array(roc_weights))\n",
    "    return area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
